version: "3.8"

services:
  llm-router:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-router
    ports:
      - "11436:11436"
    env_file:
      - .env
    volumes:
      - ./router.db:/app/router.db
    restart: unless-stopped
    networks:
      - llm-router-network

  # === Example Ollama Service ===
  # Uncomment to run Ollama as part of this compose setup.
  # Make sure ROUTER_OLLAMA_URL is set to http://ollama:11434 in your .env file.
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   environment:
  #     - OLLAMA_KEEP_ALIVE=-1
  #   restart: unless-stopped
  #   networks:
  #     - llm-router-network

volumes:
  ollama-data:

networks:
  llm-router-network:
    driver: bridge

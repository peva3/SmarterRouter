"""Pydantic models for API request/response validation."""

import re

from typing import Any, Literal

from pydantic import BaseModel, Field, field_validator


class ChatMessage(BaseModel):
    """A single chat message with validation."""
    
    role: str = Field(
        ...,
        pattern="^(user|assistant|system|tool)$", # Added tool role
        description="Role of the message sender"
    )
    content: str | list[dict[str, Any]] | None = Field( # Support multimodal content
        default=None,
        description="Message content (text or list of content parts)"
    )
    tool_calls: list[dict[str, Any]] | None = Field(default=None, description="Tool calls generated by the model")
    tool_call_id: str | None = Field(default=None, description="ID of the tool call this message responds to")
    
    @field_validator('content')
    @classmethod
    def validate_content(cls, v: Any) -> Any:
        """Validate and sanitize content."""
        if v is None:
            return v
            
        if isinstance(v, str):
            # Remove null bytes
            v = v.replace('\x00', '')
            # Simple text sanitization
            return v.strip()
            
        if isinstance(v, list):
            # Multimodal content validation
            for part in v:
                if not isinstance(part, dict):
                    raise ValueError("Content parts must be dictionaries")
                if "type" not in part:
                    raise ValueError("Content part must have a 'type'")
            return v
            
        return v


class ChatCompletionRequest(BaseModel):
    """Chat completion request with validation."""
    
    model: str | None = Field(
        default=None,
        max_length=100,
        description="Optional model override"
    )
    messages: list[ChatMessage] = Field(
        ...,
        min_length=1,
        max_length=100,
        description="List of chat messages"
    )
    stream: bool = Field(
        default=False,
        description="Whether to stream the response"
    )
    
    # Standard OpenAI parameters
    temperature: float | None = Field(default=None, ge=0.0, le=2.0)
    top_p: float | None = Field(default=None, ge=0.0, le=1.0)
    n: int | None = Field(default=None, ge=1, le=128)
    max_tokens: int | None = Field(default=None, ge=1)
    presence_penalty: float | None = Field(default=None, ge=-2.0, le=2.0)
    frequency_penalty: float | None = Field(default=None, ge=-2.0, le=2.0)
    logit_bias: dict[str, int] | None = Field(default=None)
    user: str | None = Field(default=None, max_length=100)
    seed: int | None = Field(default=None)
    logprobs: bool | None = Field(default=None)
    top_logprobs: int | None = Field(default=None, ge=0, le=20)

    tools: list[dict[str, Any]] | None = Field(default=None, description="List of available tools")
    tool_choice: str | dict[str, Any] | None = Field(default=None, description="Tool choice strategy")
    response_format: dict[str, Any] | None = Field(default=None, description="Expected response format (e.g. JSON)")
    
    @field_validator('model')
    @classmethod
    def validate_model_name(cls, v: str | None) -> str | None:
        """Validate model name doesn't contain dangerous characters."""
        if v is None:
            return v
        # Allow alphanumeric, hyphens, underscores, colons, dots, and slashes
        if not re.match(r'^[\w\-:.\/]+$', v):
            raise ValueError("Model name contains invalid characters")
        return v


class FeedbackRequest(BaseModel):
    """User feedback for a routing decision."""
    
    response_id: str | None = Field(default=None, description="The ID of the chat completion response")
    model_name: str | None = Field(default=None, description="The name of the model (optional if response_id provided)")
    score: float = Field(..., ge=-1.0, le=1.0, description="Feedback score: 1.0 (good), -1.0 (bad), or 0.0-1.0 scale")
    comment: str | None = Field(default=None, max_length=500, description="Optional comment")
    category: str | None = Field(default=None, description="Optional task category")


class EmbeddingsRequest(BaseModel):
    """OpenAI-compatible embeddings request."""
    
    model: str = Field(..., description="Model to use for embeddings")
    input: str | list[str] = Field(..., description="Input text or list of texts to embed")
    user: str | None = Field(default=None, max_length=100)
    encoding_format: Literal["float", "base64"] | None = Field(default="float")


class EmbeddingData(BaseModel):
    """Single embedding result."""
    
    object: str = "embedding"
    embedding: list[float]
    index: int


class UsageInfo(BaseModel):
    """Token usage information."""
    
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0


class EmbeddingsResponse(BaseModel):
    """OpenAI-compatible embeddings response."""
    
    object: str = "list"
    data: list[EmbeddingData]
    model: str
    usage: UsageInfo


def sanitize_prompt(prompt: str | list[dict] | None, max_length: int = 10000) -> str:
    """
    Sanitize a prompt for safe processing.
    
    Args:
        prompt: The input prompt (string or list of content parts)
        max_length: Maximum allowed length
        
    Returns:
        Sanitized prompt string
    """
    if not prompt:
        return ""
        
    # Handle list of content parts (Multimodal)
    if isinstance(prompt, list):
        text_parts = []
        for part in prompt:
            if isinstance(part, dict) and part.get("type") == "text":
                text_val = part.get("text", "")
                if isinstance(text_val, str):
                    text_parts.append(text_val)
        prompt = "\n".join(text_parts)
    
    if not isinstance(prompt, str):
        return ""
    
    # Truncate to max length
    prompt = prompt[:max_length]
    
    # Remove null bytes
    prompt = prompt.replace('\x00', '')
    
    # Remove control characters except common whitespace
    prompt = ''.join(
        c for c in prompt 
        if c in '\n\r\t' or ord(c) >= 32
    )
    
    return prompt.strip()


def sanitize_for_logging(text: str, max_length: int = 200) -> str:
    """
    Sanitize text for safe logging.
    
    Args:
        text: The text to sanitize
        max_length: Maximum length before truncation
        
    Returns:
        Sanitized text safe for logging
    """
    if not text:
        return ""
    
    # Truncate
    if len(text) > max_length:
        text = text[:max_length] + "..."
    
    # Redact potential API keys (OpenAI format: sk-...)
    text = re.sub(r'sk-[a-zA-Z0-9]{20,}', '[API_KEY_REDACTED]', text)
    
    # Redact other common secret patterns
    text = re.sub(r'[a-zA-Z0-9]{32,}', '[POTENTIAL_SECRET]', text)
    
    # Remove newlines for single-line logging
    text = text.replace('\n', ' ').replace('\r', ' ')
    
    return text


def strip_signature(content: str, signature_format: str | None = None) -> str:
    """
    Remove router signature from content.
    
    Args:
        content: The content that may contain a signature
        signature_format: The signature format string (e.g., "\nModel: {model}")
        
    Returns:
        Content without the signature
    """
    if not content:
        return content
    
    # If no format provided, try common patterns
    if not signature_format:
        # Default pattern: "\nModel: model_name" at end
        content = re.sub(r'\n?Model:.*$', '', content, flags=re.MULTILINE)
    else:
        # Escape the format string for regex
        # Convert {model} to a capture pattern
        pattern = re.escape(signature_format).replace(r'\{model\}', r'.*')
        content = re.sub(pattern + r'$', '', content, flags=re.MULTILINE)
    
    return content.rstrip()

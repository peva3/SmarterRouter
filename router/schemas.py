"""Pydantic models for API request/response validation."""

import re

from typing import Any, Literal

from pydantic import BaseModel, Field, field_validator


class ChatMessage(BaseModel):
    """A single chat message with validation."""

    role: str = Field(
        ...,
        pattern="^(user|assistant|system|tool)$",  # Added tool role
        description="Role of the message sender",
    )
    content: str | list[dict[str, Any]] | None = Field(  # Support multimodal content
        default=None, description="Message content (text or list of content parts)"
    )
    tool_calls: list[dict[str, Any]] | None = Field(
        default=None, description="Tool calls generated by the model"
    )
    tool_call_id: str | None = Field(
        default=None, description="ID of the tool call this message responds to"
    )

    @field_validator("content")
    @classmethod
    def validate_content(cls, v: Any) -> Any:
        """Validate and sanitize content."""
        if v is None:
            return v

        if isinstance(v, str):
            # Remove null bytes
            v = v.replace("\x00", "")
            # Simple text sanitization
            return v.strip()

        if isinstance(v, list):
            # Multimodal content validation
            for part in v:
                if not isinstance(part, dict):
                    raise ValueError("Content parts must be dictionaries")
                if "type" not in part:
                    raise ValueError("Content part must have a 'type'")
            return v

        return v


class ChatCompletionRequest(BaseModel):
    """Chat completion request with validation."""

    model: str | None = Field(default=None, max_length=100, description="Optional model override")
    messages: list[ChatMessage] = Field(
        ..., min_length=1, max_length=100, description="List of chat messages"
    )
    stream: bool = Field(default=False, description="Whether to stream the response")

    # Standard OpenAI parameters
    temperature: float | None = Field(default=None, ge=0.0, le=2.0)
    top_p: float | None = Field(default=None, ge=0.0, le=1.0)
    n: int | None = Field(default=None, ge=1, le=128)
    max_tokens: int | None = Field(default=None, ge=1)
    presence_penalty: float | None = Field(default=None, ge=-2.0, le=2.0)
    frequency_penalty: float | None = Field(default=None, ge=-2.0, le=2.0)
    logit_bias: dict[str, int] | None = Field(default=None)
    user: str | None = Field(default=None, max_length=100)
    seed: int | None = Field(default=None)
    logprobs: bool | None = Field(default=None)
    top_logprobs: int | None = Field(default=None, ge=0, le=20)

    tools: list[dict[str, Any]] | None = Field(default=None, description="List of available tools")
    tool_choice: str | dict[str, Any] | None = Field(
        default=None, description="Tool choice strategy"
    )
    response_format: dict[str, Any] | None = Field(
        default=None, description="Expected response format (e.g. JSON)"
    )

    @field_validator("model")
    @classmethod
    def validate_model_name(cls, v: str | None) -> str | None:
        """Validate model name doesn't contain dangerous characters."""
        if v is None:
            return v
        # Allow alphanumeric, hyphens, underscores, colons, dots, and slashes
        if not re.match(r"^[\w\-:.\/]+$", v):
            raise ValueError("Model name contains invalid characters")
        return v


class FeedbackRequest(BaseModel):
    """User feedback for a routing decision."""

    response_id: str | None = Field(
        default=None, description="The ID of the chat completion response"
    )
    model_name: str | None = Field(
        default=None, description="The name of the model (optional if response_id provided)"
    )
    score: float = Field(
        ..., ge=-1.0, le=1.0, description="Feedback score: 1.0 (good), -1.0 (bad), or 0.0-1.0 scale"
    )
    comment: str | None = Field(default=None, max_length=500, description="Optional comment")
    category: str | None = Field(default=None, description="Optional task category")


class EmbeddingsRequest(BaseModel):
    """OpenAI-compatible embeddings request."""

    model: str = Field(..., description="Model to use for embeddings")
    input: str | list[str] = Field(..., description="Input text or list of texts to embed")
    user: str | None = Field(default=None, max_length=100)
    encoding_format: Literal["float", "base64"] | None = Field(default="float")


class EmbeddingData(BaseModel):
    """Single embedding result."""

    object: str = "embedding"
    embedding: list[float]
    index: int


class UsageInfo(BaseModel):
    """Token usage information."""

    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0


class EmbeddingsResponse(BaseModel):
    """OpenAI-compatible embeddings response."""

    object: str = "list"
    data: list[EmbeddingData]
    model: str
    usage: UsageInfo


def sanitize_prompt(prompt: str | list[dict] | None, max_length: int = 10000) -> str:
    """
    Sanitize a prompt for safe processing.

    Args:
        prompt: The input prompt (string or list of content parts)
        max_length: Maximum allowed length

    Returns:
        Sanitized prompt string
    """
    if not prompt:
        return ""

    # Handle list of content parts (Multimodal)
    if isinstance(prompt, list):
        text_parts = []
        for part in prompt:
            if isinstance(part, dict) and part.get("type") == "text":
                text_val = part.get("text", "")
                if isinstance(text_val, str):
                    text_parts.append(text_val)
        prompt = "\n".join(text_parts)

    if not isinstance(prompt, str):
        return ""

    # Truncate to max length
    prompt = prompt[:max_length]

    # Remove null bytes
    prompt = prompt.replace("\x00", "")

    # Remove control characters except common whitespace
    prompt = "".join(c for c in prompt if c in "\n\r\t" or ord(c) >= 32)

    return prompt.strip()


from .logging_config import sanitize_for_logging


def strip_signature(content: str, signature_format: str | None = None) -> str:
    """
    Remove router signature from content.

    Args:
        content: The content that may contain a signature
        signature_format: The signature format string (e.g., "\nModel: {model}")

    Returns:
        Content without the signature
    """
    if not content:
        return content

    # If no format provided, try common patterns
    if not signature_format:
        # Default pattern: "\nModel: model_name" at end
        content = re.sub(r"\n?Model:.*$", "", content, flags=re.MULTILINE)
    else:
        # Escape the format string for regex
        # Convert {model} to a capture pattern
        pattern = re.escape(signature_format).replace(r"\{model\}", r".*")
        content = re.sub(pattern + r"$", "", content, flags=re.MULTILINE)

    return content.rstrip()


def _get_unclosed_fence_char(content: str) -> str | None:
    """
    Detect if content ends with an unclosed fenced code block.
    Returns the fence character ('`' or '~') if unclosed, None otherwise.
    
    Implements a proper Markdown fenced code block state machine:
    - When not in a code block, a fence line opens a block.
    - When in a code block, only an exact matching fence (3 of same char) closes it;
      any other fence is treated as content.
    """
    if not content:
        return None
    in_code = False
    current_fence = None  # '`' or '~' for the currently open block
    
    lines = content.splitlines()
    for i, line in enumerate(lines):
        stripped = line.strip()
        is_fence = stripped.startswith("```") or stripped.startswith("~~~")
        
        if is_fence:
            # Determine fence char from this line
            if stripped.startswith("```"):
                fence_char = '`'
            else:
                fence_char = '~'
                
            if not in_code:
                # Opening a new block
                in_code = True
                current_fence = fence_char
            else:
                # Inside a block: check if this line is the closing fence
                if current_fence == fence_char and stripped == fence_char * 3:
                    in_code = False
                    current_fence = None
                else:
                    # Fence inside a code block is just content; ignore for state
                    pass
    
    return current_fence if in_code else None


def is_unclosed_code_block(content: str) -> bool:
    """Check if content ends with an unclosed fenced code block."""
    return _get_unclosed_fence_char(content) is not None


def close_unclosed_code_block(content: str) -> str:
    """Close an unclosed fenced code block by appending matching fence.
    
    Special handling: if the content ends with a fence line that just opened
    an empty block (no content), remove that stray fence instead of closing it.
    This prevents ugly empty code blocks appearing before signatures.
    """
    if not content:
        return content
    
    fence_char = _get_unclosed_fence_char(content)
    if not fence_char:
        return content
    
    lines = content.splitlines()
    last_line = lines[-1].strip() if lines else ""
    
    # Check if last line is just a fence (opening with no content after)
    # In this case, remove it entirely rather than creating an empty block
    if last_line.startswith(fence_char * 3):
        # Check if this fence is just an opening with no actual content
        # (i.e., the block was just opened on the last line)
        # We detect this by counting fences - if this is the most recent one
        # and it opened a block (in_code was set), it's a stray fence
        content_stripped = "\n".join(lines[:-1]).rstrip()
        if not _get_unclosed_fence_char(content_stripped):
            # Removing the last line makes the content "closed"
            # This means the last line was a stray opening fence
            return content_stripped + "\n"
    
    # Normal case: close the unclosed block
    if not content.endswith("\n"):
        content += "\n"
    content += fence_char * 3 + "\n"
    return content
